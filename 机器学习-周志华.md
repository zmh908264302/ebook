#### 2.2 模型评估方法
1. 留出法
2. 交叉验证法
3. 自助法
***
#### 3.6 类别不平衡问题
类别不平衡指分类任务中不同类别的训练样例数目差别很大。
解决**策略**：
1. 再缩放 = 再平衡
2. 欠采样 = 下采样
3. 过采样 = 上采样
4. 阈值移动
***
#### 5.3 误差逆传播算法
1. H证明，只需一个包含足够多神经元的隐层，多层前馈网络就能以任意精度逼近任意复杂度的连续函数。然而，如何设置隐层神经元的个数仍是个未决问题，世纪应用中通常靠“试错法”调整
2. 正是由于其强大的表示能力，BP神经网络经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。两种常用策略：一种是“早停”；而是“正则化”
#### 5.4 全局最小与局部极小
如果具有多个局部极小，则不能保证找到的解是局部最小的。这种情形称为参数寻优陷入了局部极小。实际任务中“跳出”局部极小策略：
1. 以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数；
2. 使用“模拟退火”技术；
3. 使用随机梯度下降。
***
#### 6.3 核函数
***
